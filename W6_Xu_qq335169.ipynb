{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 6\n",
    "\n",
    "## Author: Peihang Xu\n",
    "\n",
    "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
    "\n",
    "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>INLAND</th>\n",
       "      <th>ISLAND</th>\n",
       "      <th>LESS_1H_OCEAN</th>\n",
       "      <th>NEAR_BAY</th>\n",
       "      <th>NEAR_OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \\\n",
       "0       322.0       126.0         8.3252            452600.0   \n",
       "1      2401.0      1138.0         8.3014            358500.0   \n",
       "2       496.0       177.0         7.2574            352100.0   \n",
       "3       558.0       219.0         5.6431            341300.0   \n",
       "4       565.0       259.0         3.8462            342200.0   \n",
       "\n",
       "   rooms_per_household  population_per_household  INLAND  ISLAND  \\\n",
       "0             6.984127                  2.555556       0       0   \n",
       "1             6.238137                  2.109842       0       0   \n",
       "2             8.288136                  2.802260       0       0   \n",
       "3             5.817352                  2.547945       0       0   \n",
       "4             6.281853                  2.181467       0       0   \n",
       "\n",
       "   LESS_1H_OCEAN  NEAR_BAY  NEAR_OCEAN  \n",
       "0              0         1           0  \n",
       "1              0         1           0  \n",
       "2              0         1           0  \n",
       "3              0         1           0  \n",
       "4              0         1           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on original features (no transformations) --- benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
      "Mean: 68945.88375656866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Support Vector Machines for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
    "\n",
    "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
    "\n",
    "However, as a hint, you can focus on C and gamma. \n",
    "\n",
    "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [0.1, 10, 10000, 100000],\n",
       "                          'gamma': [0.1, 1, 100, 1000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "C_vals = [0.1,10,10000,100000] ## YOUR VALUES FOR C ##\n",
    "gamma_vals = [0.1,1,100,1000] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=3,scoring='neg_mean_squared_error')\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100000, 'gamma': 0.1}\n",
      "Best score: 57255.36016378938\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(\"Best score:\",np.sqrt(-grid_search_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118994.53665534152 {'C': 0.1, 'gamma': 0.1}\n",
      "119015.42561724437 {'C': 0.1, 'gamma': 1}\n",
      "119017.78748915922 {'C': 0.1, 'gamma': 100}\n",
      "119017.78786776128 {'C': 0.1, 'gamma': 1000}\n",
      "116723.1737082353 {'C': 10, 'gamma': 0.1}\n",
      "118706.78465088698 {'C': 10, 'gamma': 1}\n",
      "119017.74998704392 {'C': 10, 'gamma': 100}\n",
      "119017.78784663115 {'C': 10, 'gamma': 1000}\n",
      "62439.06054204476 {'C': 10000, 'gamma': 0.1}\n",
      "77804.73236805746 {'C': 10000, 'gamma': 1}\n",
      "118996.50738233619 {'C': 10000, 'gamma': 100}\n",
      "119028.09027110973 {'C': 10000, 'gamma': 1000}\n",
      "57255.36016378938 {'C': 100000, 'gamma': 0.1}\n",
      "61010.1039625056 {'C': 100000, 'gamma': 1}\n",
      "117182.9081831695 {'C': 100000, 'gamma': 100}\n",
      "117437.63971796147 {'C': 100000, 'gamma': 1000}\n",
      "Best_parameters: {'C': 100000, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "cvres_rbf = grid_search_rbf.cv_results_\n",
    "cvres_rbf[\"mean_test_score\"]\n",
    "cvres_rbf[\"params\"]\n",
    "for mean_score, params in zip(cvres_rbf[\"mean_test_score\"], cvres_rbf[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "print(\"Best_parameters:\", grid_search_rbf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for test set: 56466.15041953528\n",
      "RMSE for train set: 54691.358731568034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
    "\n",
    "y_te_estimation = final_model.predict(X_te)\n",
    "y_tr_estimation = final_model.predict(X_tr)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"RMSE for test set:\",final_rmse)\n",
    "final_mse_tr = mean_squared_error(y_tr, y_tr_estimation)\n",
    "final_rmse_tr = np.sqrt(final_mse_tr)\n",
    "print(\"RMSE for train set:\",final_rmse_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As expected, RMSE for train is slightly higher for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM for Classification\n",
    "\n",
    "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Filter convergence warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(housing[['median_house_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
    "y_te_b = 1*np.ravel(y_te>=179700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 0.8385935769656699\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_tr)\n",
    "print('Accuracy score for training set:',accuracy_score(y_tr_b, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set: 0.8389857881136951\n"
     ]
    }
   ],
   "source": [
    "y_pred_te = lin_clf.predict(X_te)\n",
    "print('Accuracy score for test set:',accuracy_score(y_te_b, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8386166219228823"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score expects \n",
    "roc_auc_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosss validation scores: 0.8374859514075578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Linear_SVC_scores = cross_val_score(lin_clf, X_tr, y_tr_b,\n",
    "                         scoring=\"accuracy\", cv=3)\n",
    "\n",
    "print('Crosss validation scores:',Linear_SVC_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf = SVC()\n",
    "SVC_clf.fit(X_tr, y_tr_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866140642303433"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SVC = SVC_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosss validation scores: 0.8590802051873722\n"
     ]
    }
   ],
   "source": [
    "SVC_scores = cross_val_score(SVC_clf, X_tr, y_tr_b,\n",
    "                         scoring=\"accuracy\", cv=3)\n",
    "\n",
    "print('Crosss validation scores:',SVC_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 0.866140642303433\n",
      "Accuracy score for test set: 0.8624031007751938\n"
     ]
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict(X_tr)\n",
    "print('Accuracy score for training set:',accuracy_score(y_tr_b, y_pred))\n",
    "y_pred_te = SVC_clf.predict(X_te)\n",
    "print('Accuracy score for test set:',accuracy_score(y_te_b, y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy increases a little bit comparing to Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                 coef0=0.0, decision_function_shape='ovr',\n",
       "                                 degree=3, gamma='auto', kernel='rbf',\n",
       "                                 max_iter=-1, probability=False,\n",
       "                                 random_state=None, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='warn', n_iter=5, n_jobs=None,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10d304bd0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'C': randint(low=1, high=200),\n",
    "    }\n",
    "\n",
    "SVC_clf_rd = SVC(kernel = 'rbf',gamma = 'auto')\n",
    "rnd_search = RandomizedSearchCV(SVC_clf_rd, param_distribs,\n",
    "                                n_iter=5, cv=3, scoring='accuracy', random_state=42)\n",
    "rnd_search.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874031007751938 {'C': 103}\n",
      "0.873062015503876 {'C': 180}\n",
      "0.8737541528239202 {'C': 93}\n",
      "0.8695321151716501 {'C': 15}\n",
      "0.8741002214839424 {'C': 107}\n",
      "Best_parameters: {'C': 107}\n",
      "{'C': 107}\n",
      "Best cross validation score: 0.8741002214839424\n"
     ]
    }
   ],
   "source": [
    "cvres_SVC = rnd_search.cv_results_\n",
    "cvres_SVC[\"mean_test_score\"]\n",
    "cvres_SVC[\"params\"]\n",
    "for mean_score, params in zip(cvres_SVC[\"mean_test_score\"], cvres_SVC[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best_parameters:\", rnd_search.best_params_)\n",
    "print(rnd_search.best_params_)\n",
    "print(\"Best cross validation score:\",rnd_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 0.9004014396456257\n",
      "Accuracy score for test set: 0.8766149870801033\n"
     ]
    }
   ],
   "source": [
    "final_model_SVC = rnd_search.best_estimator_\n",
    "\n",
    "y_pred = final_model_SVC.predict(X_tr)\n",
    "print('Accuracy score for training set:',accuracy_score(y_tr_b, y_pred))\n",
    "y_pred_te = final_model_SVC.predict(X_te)\n",
    "print('Accuracy score for test set:',accuracy_score(y_te_b, y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance improves as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Train a Logistic Regression (search teh best hyper-parameters) and compare its performance with SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 100, 1000], 'max_iter': [100, 1000, 10000],\n",
       "                         'solver': ['lbfgs', 'sag', 'liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(class_weight = 'balanced')\n",
    "lr_clf.fit(X_tr, y_tr_b)\n",
    "\n",
    "# y_pred_lr = lr_clf.predict(X_tr)\n",
    "# accuracy_score(y_tr_b, y_pred_lr)\n",
    "\n",
    "param_distribs = {\n",
    "        'C': [1,100,1000],\n",
    "        'solver': ['lbfgs','sag','liblinear'],\n",
    "        'max_iter':[100,1000,10000],\n",
    "    }\n",
    "\n",
    "lr_clf_gs = LogisticRegression(class_weight = 'balanced')\n",
    "grid_search_lr = GridSearchCV(lr_clf_gs, param_distribs,\n",
    "                             cv=3, scoring='accuracy')\n",
    "grid_search_lr.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8376937984496124 {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "0.8365863787375415 {'C': 1, 'max_iter': 100, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.8376937984496124 {'C': 1, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8375553709856035 {'C': 1, 'max_iter': 1000, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.8376937984496124 {'C': 1, 'max_iter': 10000, 'solver': 'lbfgs'}\n",
      "0.8375553709856035 {'C': 1, 'max_iter': 10000, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1, 'max_iter': 10000, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "0.8366555924695459 {'C': 100, 'max_iter': 100, 'solver': 'sag'}\n",
      "0.8378322259136213 {'C': 100, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 100, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8377630121816169 {'C': 100, 'max_iter': 1000, 'solver': 'sag'}\n",
      "0.8378322259136213 {'C': 100, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 100, 'max_iter': 10000, 'solver': 'lbfgs'}\n",
      "0.8377630121816169 {'C': 100, 'max_iter': 10000, 'solver': 'sag'}\n",
      "0.8378322259136213 {'C': 100, 'max_iter': 10000, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 1000, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "0.8366555924695459 {'C': 1000, 'max_iter': 100, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1000, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 1000, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8377630121816169 {'C': 1000, 'max_iter': 1000, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1000, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "0.8377630121816169 {'C': 1000, 'max_iter': 10000, 'solver': 'lbfgs'}\n",
      "0.8377630121816169 {'C': 1000, 'max_iter': 10000, 'solver': 'sag'}\n",
      "0.8376937984496124 {'C': 1000, 'max_iter': 10000, 'solver': 'liblinear'}\n",
      "Best_parameters: {'C': 100, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "{'C': 100, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Best cross validation score: 0.8378322259136213\n"
     ]
    }
   ],
   "source": [
    "cvres_lr = grid_search_lr.cv_results_\n",
    "cvres_lr[\"mean_test_score\"]\n",
    "cvres_lr[\"params\"]\n",
    "for mean_score, params in zip(cvres_lr[\"mean_test_score\"], cvres_lr[\"params\"]):\n",
    "    print(mean_score, params)\n",
    "print(\"Best_parameters:\", grid_search_lr.best_params_)\n",
    "print(grid_search_lr.best_params_)\n",
    "print('Best cross validation score:',grid_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 0.8387320044296789\n",
      "Accuracy score for test set: 0.8409237726098191\n"
     ]
    }
   ],
   "source": [
    "final_model_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "y_pred = final_model_lr.predict(X_tr)\n",
    "print('Accuracy score for training set:',accuracy_score(y_tr_b, y_pred))\n",
    "y_pred_te = final_model_lr.predict(X_te)\n",
    "print('Accuracy score for test set:',accuracy_score(y_te_b, y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The performance of logistic regression is worse than using SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
