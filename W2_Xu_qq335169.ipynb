{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Peihang Xu</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> N/A</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the housing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SHAPE: (20640, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "print(\"DATA SHAPE:\", housing.shape)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build full pipeline for the data analysis following the example of the notebook.\n",
    " Hint: the main part requested to change is the algorithm used (KNN regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for building pipeline:\n",
    "\n",
    "- Make your notebook as compact as possible. \n",
    "- Split data into training and testing sets below.\n",
    "- Convert all categorical data to one-hot vectors below\n",
    "- Normalize all non-categorical data \n",
    "-  Perform KNN regression using a variety of values for n_neighbors (K) between 1 and 10 and both \"uniform\" and \"distance\" weights via a grid search where  *housing_labels* is the output and all other features are the input (similar to as seen in lecture two.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified split the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide by 1.5 to limit the number of income categories \n",
    "# adding a new attribute here called \"income_cat\"\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "# Label those above 5 as 5\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Strat. %error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.039826</td>\n",
       "      <td>0.039729</td>\n",
       "      <td>-0.243309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.318847</td>\n",
       "      <td>0.318798</td>\n",
       "      <td>-0.015195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.350581</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>-0.013820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.176357</td>\n",
       "      <td>0.027480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.114438</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.127011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall  Stratified  Strat. %error\n",
       "1.0  0.039826    0.039729      -0.243309\n",
       "2.0  0.318847    0.318798      -0.015195\n",
       "3.0  0.350581    0.350533      -0.013820\n",
       "4.0  0.176308    0.176357       0.027480\n",
       "5.0  0.114438    0.114583       0.127011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "from sklearn.model_selection import train_test_split\n",
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.7042</td>\n",
       "      <td>286600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4214</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.20</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.8621</td>\n",
       "      <td>196900.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1.8839</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>3.0347</td>\n",
       "      <td>254500.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "17606    -121.89     37.29                38.0       1568.0           351.0   \n",
       "18632    -121.93     37.05                14.0        679.0           108.0   \n",
       "14650    -117.20     32.77                31.0       1952.0           471.0   \n",
       "3230     -119.61     36.31                25.0       1847.0           371.0   \n",
       "3555     -118.59     34.23                17.0       6592.0          1525.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "17606       710.0       339.0         2.7042            286600.0   \n",
       "18632       306.0       113.0         6.4214            340600.0   \n",
       "14650       936.0       462.0         2.8621            196900.0   \n",
       "3230       1460.0       353.0         1.8839             46300.0   \n",
       "3555       4459.0      1463.0         3.0347            254500.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "17606       <1H OCEAN  \n",
       "18632       <1H OCEAN  \n",
       "14650      NEAR OCEAN  \n",
       "3230           INLAND  \n",
       "3555        <1H OCEAN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the \"income_cat\" attribute after splitting\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a full transformation pipeline to impute missing components, convert all categorical data to one-hot vectors, and normalize all non-categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Firstly impute missing values and do min-max scaling\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "housing_num = housing.drop('ocean_proximity', axis=1) # Define a dataframe with only numerical attributes\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"] # Lists of numerical/categorical attribute names\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), #impute\n",
    "        ('std_scaler', MinMaxScaler(feature_range=(0, 1))), # then normalize\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num) #transform housing_num daata frame to an np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here define a full pipeline transformer to transform the whole training dataset all at once\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement KNN regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "KNN_reg = KNeighborsRegressor()\n",
    "KNN_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [60650.94168635 62650.20957684 63775.61883886 63071.65536651\n",
      " 62127.10348079 64943.97508527 60860.88448428 63456.28743377\n",
      " 63959.71438229 64183.52086099]\n",
      "Mean: 62967.99111959522\n",
      "Standard deviation: 1337.2986163439268\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for 10-fold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "\n",
    "KNN_scores = cross_val_score(KNN_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "KNN_rmse_scores = np.sqrt(-KNN_scores)\n",
    "display_scores(KNN_rmse_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       10.000000\n",
       "mean     62967.991120\n",
       "std       1409.636513\n",
       "min      60650.941686\n",
       "25%      62257.880005\n",
       "50%      63263.971400\n",
       "75%      63913.690496\n",
       "max      64943.975085\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or use this to display the cross validation results\n",
    "scores = cross_val_score(KNN_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10, 'weights': 'distance'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    # try 4 (2Ã—2) combinations of hyperparameters\n",
    "    {'n_neighbors': [1, 10], 'weights': ['uniform','distance']}\n",
    "  ]\n",
    "\n",
    "grid_search = GridSearchCV(KNN_reg, param_grid, cv=10, #totally 40 rounds of training since 2x2x10\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76075.60050887972 {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "76075.60050887972 {'n_neighbors': 1, 'weights': 'distance'}\n",
      "62355.70276799552 {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "61560.95930357948 {'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "cvres[\"mean_test_score\"]\n",
    "cvres[\"params\"]\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([456014.43182275, 279271.4193661 , 269806.65401908, ...,\n",
       "       296076.79043123, 160226.91641625, 104495.70479672])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test) # no fit here!\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10, 'weights': 'distance'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58209.0555843 , 62683.38636523])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "mean = squared_errors.mean()\n",
    "m = len(squared_errors)\n",
    "\n",
    "np.sqrt(stats.t.interval(confidence, m - 1,\n",
    "                         loc=np.mean(squared_errors),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A full pipeline with both preparation and prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preparation',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('std_scaler',\n",
       "                                                                   MinMaxScaler(copy=True,\n",
       "                                                                                feature_...\n",
       "                                                   'population', 'households',\n",
       "                                                   'median_income']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['ocean_proximity'])],\n",
       "                                   verbose=False)),\n",
       "                ('KNN_reg',\n",
       "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                     metric='minkowski', metric_params=None,\n",
       "                                     n_jobs=None, n_neighbors=10, p=2,\n",
       "                                     weights='distance'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('KNN_reg', KNeighborsRegressor(**grid_search.best_params_))\n",
    "])\n",
    "prepare_select_and_predict_pipeline.fit(housing,housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\t [456014.43182275 279271.4193661  269806.65401908 ... 296076.79043123\n",
      " 160226.91641625 104495.70479672]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\\t\", prepare_select_and_predict_pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "For what values of n_neighbors and weight does KNeighborsRegressor perform the best? Does it perform as well on the housing data as the linear regressor from the lectures? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "I found the best hyperparameter values to be n_neighbors = 10 and weights = 'distance'.\n",
    "\n",
    "The final mean score of the two algorithms gives 69052.46136345083 for linear regressor and 61560.95930357948    for KNeighborsRegressor after grid search.\n",
    "\n",
    "By comparing them, I think KNeighborsRegressor performs slightly better than linear regressor due to a lower      value of score.\n",
    "\n",
    "The difference here can be caused by a few reasons: \n",
    "   1. in my homework calculation, I do not include some added attributes such as rooms_per_household and\n",
    "      population_per_household\n",
    "   2. for linear regressor, in the class we did not try to fine-tune the hyperparameters using grid search or \n",
    "      random search\n",
    "   3. The feature scaling method used here is noramalization (min-max scaler) instead of standarzation, which         \n",
    "      means it could be more affected by outliers \n",
    "   4. the property of the data itself may just determines that it would work better with KNeighborRegressor \n",
    "   \n",
    "\n",
    "   \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read appending B\n",
    "\n",
    "- Reflect on your last data project, read appendix B. Then, write down a few of the checklist items that your last data project could have used. If you have not yet done a data project, then write down a few of the items that you found most interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "I am still a physics Ph.D. candidate and very new to this field. So I have never really done a data project. In my physics study, I take and analyze experimental data, and usually just use matlab to do a fit to the theory     model.\n",
    "However in the data science field, all data are more realistic and fitting results can be applied to everyday   life. \n",
    "So in this application, trying to clean the data, find a good machine learning algorithm, and tune the model are critical. They play an important role for accuracy of the prediction. The predictions can then be applied to    important applications such as decisions for investments. \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "<pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your notebook\n",
    "\n",
    "Submit your solution to Quercus\n",
    "Make sure you rename your notebook to    \n",
    "W2_UTORid.ipynb    \n",
    "Example W2_adfasd01.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
