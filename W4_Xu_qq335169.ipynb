{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 4, Training Models\n",
    "\n",
    "In this assignment you will train different models on a given data set, and find the one that performs best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR_BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR_BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR_BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR_BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR_BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR_BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR_BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR_BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR_BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR_BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>INLAND</th>\n",
       "      <th>ISLAND</th>\n",
       "      <th>LESS_1H_OCEAN</th>\n",
       "      <th>NEAR_BAY</th>\n",
       "      <th>NEAR_OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \\\n",
       "0       322.0       126.0         8.3252            452600.0   \n",
       "1      2401.0      1138.0         8.3014            358500.0   \n",
       "2       496.0       177.0         7.2574            352100.0   \n",
       "3       558.0       219.0         5.6431            341300.0   \n",
       "4       565.0       259.0         3.8462            342200.0   \n",
       "\n",
       "   rooms_per_household  population_per_household  INLAND  ISLAND  \\\n",
       "0             6.984127                  2.555556       0       0   \n",
       "1             6.238137                  2.109842       0       0   \n",
       "2             8.288136                  2.802260       0       0   \n",
       "3             5.817352                  2.547945       0       0   \n",
       "4             6.281853                  2.181467       0       0   \n",
       "\n",
       "   LESS_1H_OCEAN  NEAR_BAY  NEAR_OCEAN  \n",
       "0              0         1           0  \n",
       "1              0         1           0  \n",
       "2              0         1           0  \n",
       "3              0         1           0  \n",
       "4              0         1           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "Using the familiar California housing dataset (target = 'median_house_value'), train several models using various regularization techniques to improve model accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Partition into train and test\n",
    "\n",
    "Use `train_test_split` from `sklearn.model_selection` to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# target_col = 'median_house_value'\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)\n",
    "housing_tr = train_set.drop('median_house_value',axis = 1)\n",
    "housing_tr_label = train_set['median_house_value'].values \n",
    "housing_test = test_set.drop('median_house_value',axis = 1)\n",
    "housing_test_target =  test_set['median_house_value'].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Polynomial transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PolynomialFeatures from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2)\n",
    "housing_tr_poly = pf.fit_transform(housing_tr)\n",
    "housing_test_poly = pf.fit_transform(housing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You should obtain X_train and X_test with 136 columns each, since originally you had 15 features.\n",
    "\n",
    "##### With m original features, the new added polynomial features of degree 2 are: $(m^2-m)/2+m+1$.\n",
    "\n",
    "##### These, plus the original features gives a total of  $(m^2-m)/2+2m+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set original number of features: 15\n",
      "Train set final number of features: 136\n",
      "Test set original number of features: 15\n",
      "Test set final number of features: 136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14448"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train set original number of features: \"+str(housing_tr.shape[1]))\n",
    "print(\"Train set final number of features: \"+str(housing_tr_poly.shape[1]))\n",
    "print(\"Test set original number of features: \"+str(housing_test.shape[1]))\n",
    "print(\"Test set final number of features: \"+str(housing_test_poly.shape[1]))\n",
    "len(housing_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use `StandardScaler` from `sklearn.preprocessing` to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SS = StandardScaler()\n",
    "housing_tr_poly_ss = SS.fit_transform(housing_tr_poly)\n",
    "housing_tr_ss = SS.fit_transform(housing_tr)\n",
    "housing_tr_ss_b = np.c_[np.ones((len(housing_tr), 1)), housing_tr_ss] \n",
    "# add x0 = 1 to each instance, and it has to be there to be dimensionaly correct for home built algorithms!\n",
    "\n",
    "housing_test_poly_ss = SS.fit_transform(housing_test_poly)\n",
    "housing_test_ss = SS.fit_transform(housing_test)\n",
    "housing_test_ss_b = np.c_[np.ones((len(housing_test), 1)), housing_test_ss]\n",
    "# add x0 = 1 to each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.26245997,  0.22100564, ..., -0.88597541,\n",
       "        -0.3480371 , -0.40188078],\n",
       "       [ 1.        ,  0.0379687 , -0.20974655, ..., -0.88597541,\n",
       "        -0.3480371 , -0.40188078],\n",
       "       [ 1.        , -1.44866235,  1.03568912, ..., -0.88597541,\n",
       "         2.87325693, -0.40188078],\n",
       "       ...,\n",
       "       [ 1.        ,  0.8112164 , -0.89801363, ...,  1.12869949,\n",
       "        -0.3480371 , -0.40188078],\n",
       "       [ 1.        , -0.86997375,  1.0450533 , ..., -0.88597541,\n",
       "        -0.3480371 , -0.40188078],\n",
       "       [ 1.        ,  0.64658947, -0.67327336, ...,  1.12869949,\n",
       "        -0.3480371 , -0.40188078]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_test_ss_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models\n",
    "\n",
    "Use this function to display your cross val scores, or you may use your own custom function.\n",
    "\n",
    "**Either way it is important to display your results as you train new models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Cross_validation_scores:\", scores)\n",
    "    print(\"Cross_validation_mean_score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Linear regression on original features (no transformations) --- benchmark\n",
    "\n",
    "Train a simple linear regression model using `cross_val_score` with no regularization or feature transformations. This model will serve as your benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Try to make my own model using SGD, and compare with sklearn SGDRegressor (similar to codes in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def learning_schedule(t, t0=5, t1=50):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "class SGD_Scratch(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, eta=0.01, use_lrs=True, n_epochs=100, max_iter=1000, randomstate = 42): # no *args or **kargs\n",
    "        self.use_lrs = use_lrs\n",
    "        self.eta = eta\n",
    "        self.n_epochs = n_epochs\n",
    "        self.max_iter = max_iter\n",
    "        self.randomstate = randomstate\n",
    "        self.theta = []\n",
    "    def fit(self, X,y):\n",
    "        np.random.seed(self.randomstate)\n",
    "        feature = X.shape[1]\n",
    "        theta = np.random.randn(feature,1)  # random initialization\n",
    "        thetas = []\n",
    "        g_bias = []\n",
    "        g_theta = []\n",
    "        mses = []\n",
    "        m = X.shape[0]\n",
    "        t=0\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for i in range(m):\n",
    "                random_index = np.random.randint(m)\n",
    "                xi = X[random_index:random_index+1]\n",
    "                yi = y[random_index:random_index+1]\n",
    "                gradients = 2 * xi.T.dot(xi.dot(theta) - yi)  # Calc derivatives\n",
    "                eta = self.eta\n",
    "                if self.use_lrs:\n",
    "                    eta = learning_schedule(t) # Calc lr\n",
    "                theta = theta - eta * gradients # Update step\n",
    "                y_hat = X.dot(theta) # Make Preds\n",
    "                mse = mean_squared_error(y, y_hat)\n",
    "                # Append values\n",
    "                thetas.append(theta)\n",
    "                g_bias.append(gradients[0][0])\n",
    "                g_theta.append(gradients[1][0])\n",
    "                mses.append(mse)\n",
    "                thetas.append(theta)\n",
    "                t += 1 # Normally this would be done on every epoch, not iteration\n",
    "                if len(g_bias)==self.max_iter:\n",
    "                    self.theta = theta\n",
    "                    return theta                \n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    def predict(self,X):\n",
    "        return X.dot(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_for_train =  5459045.6481383685\n",
      "MSE_for_train =  29801179388458.465\n",
      "Cross_validation_scores: [ 374994.56809858 1435693.59964166 1580239.67880478  424849.30480137\n",
      "  521932.0279239 ]\n",
      "Cross_validation_mean_score: 867541.8358540576\n"
     ]
    }
   ],
   "source": [
    "SGD_mine = SGD_Scratch(use_lrs= True)\n",
    "SGD_mine.fit(housing_tr_ss_b, housing_tr_label)\n",
    "print(\"RMSE_for_train = \", np.sqrt(mean_squared_error(SGD_mine.predict(housing_tr_ss_b),housing_tr_label)))\n",
    "print(\"MSE_for_train = \", mean_squared_error(SGD_mine.predict(housing_tr_ss_b),housing_tr_label))\n",
    "scores_SGDmine = cross_val_score(SGD_mine, housing_tr_ss_b, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "SGD_mine_scores = np.sqrt(-scores_SGDmine)\n",
    "display_scores(SGD_mine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_for_train =  1030112622.9277354\n",
      "MSE_for_train =  1.061132015915059e+18\n",
      "Cross_validation_scores: [1.41066092e+08 2.28592427e+08 7.88618493e+06 1.64375294e+07\n",
      " 6.57713823e+07]\n",
      "Cross_validation_mean_score: 91950723.17952481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.01, random_state=42)\n",
    "sgd_reg.fit(housing_tr_ss, housing_tr_label.ravel())\n",
    "# print(\"THETA:\", sgd_reg.intercept_, sgd_reg.coef_)\n",
    "print(\"RMSE_for_train = \", np.sqrt(mean_squared_error(sgd_reg.predict(housing_tr_ss),housing_tr_label)))\n",
    "print(\"MSE_for_train = \", mean_squared_error(sgd_reg.predict(housing_tr_ss),housing_tr_label))\n",
    "\n",
    "scores_SGD = cross_val_score(sgd_reg, housing_tr_ss_b, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "SGD_scores = np.sqrt(-scores_SGD)\n",
    "display_scores(SGD_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: So both models give very bad scores, in general SGD model does not work well here at all. Will not use them later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Try to make my own model of Linear Regression, and compare with Sklearn LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Scratch(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rcond=1e-6): # no *args or **kargs\n",
    "        self.rcond = rcond\n",
    "        self.theta = []\n",
    "    def fit(self, X,y):\n",
    "        theta, residuals, rank, s = np.linalg.lstsq(X, y, rcond=self.rcond) \n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    def predict(self,X):\n",
    "        return X.dot(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_for_train =  68644.23696770654\n",
      "MSE_for_train =  4712031268.878649\n",
      "Cross_validation_scores: [69999.9203722  67623.99050777 67765.44971309 67790.17691622\n",
      " 71955.71133061]\n",
      "Cross_validation_mean_score: 69027.04976797673\n"
     ]
    }
   ],
   "source": [
    "lin_mine = LR_Scratch()\n",
    "lin_mine.fit(housing_tr_ss_b, housing_tr_label)\n",
    "# print(\"THETA:\", lin_reg.intercept_, lin_reg.coef_)\n",
    "print(\"RMSE_for_train = \", np.sqrt(mean_squared_error(lin_mine.predict(housing_tr_ss_b),housing_tr_label)))\n",
    "print(\"MSE_for_train = \", mean_squared_error(lin_mine.predict(housing_tr_ss_b),housing_tr_label))\n",
    "scores_LRmin = cross_val_score(lin_mine, housing_tr_ss_b, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "LR_mine_scores = np.sqrt(-scores_LRmin)\n",
    "display_scores(LR_mine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_for_train =  68644.23696770654\n",
      "MSE_for_train =  4712031268.878649\n",
      "Cross_validation_scores: [69999.9203722  67624.84547762 67765.44971309 67790.17691622\n",
      " 71955.71133061]\n",
      "Cross_validation_mean_score: 69027.2207619483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_tr_ss, housing_tr_label)\n",
    "# print(\"THETA:\", lin_reg.intercept_, lin_reg.coef_)\n",
    "print(\"RMSE_for_train = \", np.sqrt(mean_squared_error(lin_reg.predict(housing_tr_ss),housing_tr_label)))\n",
    "print(\"MSE_for_train = \", mean_squared_error(lin_reg.predict(housing_tr_ss),housing_tr_label))\n",
    "scores_LR = cross_val_score(lin_reg, housing_tr_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "LR_scores = np.sqrt(-scores_LR)\n",
    "display_scores(LR_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### They both give same results as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69027.220762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear_Regression\n",
       "0       69027.220762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Linear_Regression\":[LR_scores.mean()],\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear regression  (on transformed features: polynomial transformation + scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do as in **2.1** but with the original and transformed features (136 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_for_train =  60403.90013237272\n",
      "MSE_for_train =  3648631151.2016573\n",
      "Cross_validation_scores: [2.50548206e+15 6.15472277e+04 5.11355407e+14 5.92952502e+04\n",
      " 3.15091693e+14]\n",
      "Cross_validation_mean_score: 666385832910306.6\n"
     ]
    }
   ],
   "source": [
    "lin_reg_poly = LinearRegression()\n",
    "lin_reg_poly.fit(housing_tr_poly_ss, housing_tr_label)\n",
    "# print(\"THETA:\", lin_reg_poly.intercept_, lin_reg_poly.coef_)\n",
    "print(\"RMSE_for_train = \", np.sqrt(mean_squared_error(lin_reg_poly.predict(housing_tr_poly_ss),housing_tr_label)))\n",
    "print(\"MSE_for_train = \", mean_squared_error(lin_reg_poly.predict(housing_tr_poly_ss),housing_tr_label))\n",
    "scores_poly = cross_val_score(lin_reg_poly, housing_tr_poly_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "LR_scores_poly = np.sqrt(-scores_poly)\n",
    "display_scores(LR_scores_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Regression</th>\n",
       "      <th>Linear_Regression_poly_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69027.220762</td>\n",
       "      <td>6.663858e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear_Regression  Linear_Regression_poly_features\n",
       "0       69027.220762                     6.663858e+14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Linear_Regression\":[LR_scores.mean()],\n",
    "             \"Linear_Regression_poly_features\": [LR_scores_poly.mean()]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge regression\n",
    "\n",
    "Using the same transformed dataset from **2.2**, train another linear model but this time apply L2 regularization. Run the model through grid search to find the optimal regularization hyperparams. Print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=42,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'alpha': [1, 2, 3],\n",
       "                          'solver': ['cholesky', 'sag', 'auto']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(random_state=42)\n",
    "param_grid = [\n",
    "    # try 9 (3×3) combinations of hyperparameters\n",
    "    {'alpha': [1,2,3], 'solver': ['cholesky', 'sag','auto']}\n",
    "  ]\n",
    "grid_search_ridge = GridSearchCV(ridge_reg, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_ridge.fit(housing_tr_poly_ss, housing_tr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135620.43099600772 {'alpha': 1, 'solver': 'cholesky'}\n",
      "69793.86643089689 {'alpha': 1, 'solver': 'sag'}\n",
      "135620.43099600772 {'alpha': 1, 'solver': 'auto'}\n",
      "112013.55029055574 {'alpha': 2, 'solver': 'cholesky'}\n",
      "69749.64138069829 {'alpha': 2, 'solver': 'sag'}\n",
      "112013.55029055574 {'alpha': 2, 'solver': 'auto'}\n",
      "100995.44367345599 {'alpha': 3, 'solver': 'cholesky'}\n",
      "69706.90249312554 {'alpha': 3, 'solver': 'sag'}\n",
      "100995.44367345599 {'alpha': 3, 'solver': 'auto'}\n",
      "Best_parameters: {'alpha': 3, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "cvres_ridge = grid_search_ridge.cv_results_\n",
    "cvres_ridge[\"mean_test_score\"]\n",
    "cvres_ridge[\"params\"]\n",
    "for mean_score, params in zip(cvres_ridge[\"mean_test_score\"], cvres_ridge[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "print(\"Best_parameters:\", grid_search_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation_scores: [65234.40764205 63859.98731357 88761.98171921 63453.04911746\n",
      " 68242.64314208]\n",
      "Cross_validation_mean_score: 69910.41378687636\n"
     ]
    }
   ],
   "source": [
    "final_ridge_model = grid_search_ridge.best_estimator_ \n",
    "scores_Ridge = cross_val_score(final_ridge_model, housing_tr_poly_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "Ridge_scores = np.sqrt(-scores_Ridge)\n",
    "display_scores(Ridge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Regression</th>\n",
       "      <th>Linear_Regression_poly_features</th>\n",
       "      <th>Ridge_Regression_poly_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69027.220762</td>\n",
       "      <td>6.663858e+14</td>\n",
       "      <td>69910.413787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear_Regression  Linear_Regression_poly_features  \\\n",
       "0       69027.220762                     6.663858e+14   \n",
       "\n",
       "   Ridge_Regression_poly_features  \n",
       "0                    69910.413787  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Linear_Regression\":[LR_scores.mean()],\n",
    "             \"Linear_Regression_poly_features\": [LR_scores_poly.mean()],\n",
    "             \"Ridge_Regression_poly_features\": [Ridge_scores.mean()]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: It seems that we would like to have as big alpha as possible. This indicates that the model has such a high variance that you need strong l2 regularization. Thus adding some l1 regularization is necessory! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lasso regression\n",
    "\n",
    "Now do the same as in **2.3** but with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=42,\n",
       "                             selection='cyclic', tol=-inf, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'alpha': [1, 2, 3], 'max_iter': [1000, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(random_state=42,tol = -np.inf)\n",
    "param_grid = [\n",
    "    # try 6 (3×2) combinations of hyperparameters\n",
    "    {'alpha': [1,2,3], 'max_iter': [1000,100]}\n",
    "  ]\n",
    "grid_search_lasso = GridSearchCV(lasso_reg, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_lasso.fit(housing_tr_poly_ss, housing_tr_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97934.45619757366 {'alpha': 1, 'max_iter': 1000}\n",
      "72282.85857162773 {'alpha': 1, 'max_iter': 100}\n",
      "93348.9431310735 {'alpha': 2, 'max_iter': 1000}\n",
      "72154.75418786789 {'alpha': 2, 'max_iter': 100}\n",
      "89111.80836889031 {'alpha': 3, 'max_iter': 1000}\n",
      "72022.66985640622 {'alpha': 3, 'max_iter': 100}\n",
      "Best_parameters: {'alpha': 3, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "cvres_lasso = grid_search_lasso.cv_results_\n",
    "cvres_lasso[\"mean_test_score\"]\n",
    "cvres_lasso[\"params\"]\n",
    "for mean_score, params in zip(cvres_lasso[\"mean_test_score\"], cvres_lasso[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "print(\"Best_parameters:\", grid_search_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation_scores: [65672.98649736 63637.87776364 71976.1971317  62449.77816796\n",
      " 93450.72512275]\n",
      "Cross_validation_mean_score: 71437.5129366835\n"
     ]
    }
   ],
   "source": [
    "final_lasso_model = grid_search_lasso.best_estimator_ \n",
    "scores_Lasso = cross_val_score(final_lasso_model, housing_tr_poly_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "Lasso_scores = np.sqrt(-scores_Lasso)\n",
    "display_scores(Lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Regression</th>\n",
       "      <th>Linear_Regression_poly_features</th>\n",
       "      <th>Ridge_Regression_poly_features</th>\n",
       "      <th>Lasso_Regression_poly_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69027.220762</td>\n",
       "      <td>6.663858e+14</td>\n",
       "      <td>69910.413787</td>\n",
       "      <td>71437.512937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear_Regression  Linear_Regression_poly_features  \\\n",
       "0       69027.220762                     6.663858e+14   \n",
       "\n",
       "   Ridge_Regression_poly_features  Lasso_Regression_poly_features  \n",
       "0                    69910.413787                    71437.512937  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Linear_Regression\":[LR_scores.mean()],\n",
    "             \"Linear_Regression_poly_features\": [LR_scores_poly.mean()],\n",
    "             \"Ridge_Regression_poly_features\": [Ridge_scores.mean()],\n",
    "             \"Lasso_Regression_poly_features\": [Lasso_scores.mean()]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: Here it seems that we would like to have as big alpha as possible again. This again indicates that the model has such a high variance that you need strong l1 regularization. Thus adding both l1 and l2 regularization is necessory! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Elastic Net regression\n",
    "\n",
    "Do the same as in **2.3** and **2.4**, but now with Elastic Net. However, the grid search should be over the parameters alpha and  L1 ratio. Use just 3 values for L1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=42, selection='cyclic', tol=-inf,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'alpha': [1, 2, 3],\n",
       "                          'l1_ratio': [0.2, 0.4, 0.6, 0.8]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(random_state=42,tol = -np.inf)\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'alpha': [1,2,3], 'l1_ratio': [0.2, 0.4, 0.6, 0.8]}\n",
    "  ]\n",
    "grid_search_EN = GridSearchCV(elastic_net, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_EN.fit(housing_tr_poly_ss, housing_tr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70246.62635970213 {'alpha': 1, 'l1_ratio': 0.2}\n",
      "69584.22286958835 {'alpha': 1, 'l1_ratio': 0.4}\n",
      "68792.5067227347 {'alpha': 1, 'l1_ratio': 0.6}\n",
      "67763.82778279544 {'alpha': 1, 'l1_ratio': 0.8}\n",
      "72378.0503247321 {'alpha': 2, 'l1_ratio': 0.2}\n",
      "71378.43461909039 {'alpha': 2, 'l1_ratio': 0.4}\n",
      "70247.20995056114 {'alpha': 2, 'l1_ratio': 0.6}\n",
      "68793.29237629476 {'alpha': 2, 'l1_ratio': 0.8}\n",
      "74184.74988275983 {'alpha': 3, 'l1_ratio': 0.2}\n",
      "72849.46400299396 {'alpha': 3, 'l1_ratio': 0.4}\n",
      "71378.99746365364 {'alpha': 3, 'l1_ratio': 0.6}\n",
      "69585.44000496586 {'alpha': 3, 'l1_ratio': 0.8}\n",
      "Best_parameters: {'alpha': 1, 'l1_ratio': 0.8}\n"
     ]
    }
   ],
   "source": [
    "cvres_EN = grid_search_EN.cv_results_\n",
    "cvres_EN[\"mean_test_score\"]\n",
    "cvres_EN[\"params\"]\n",
    "for mean_score, params in zip(cvres_EN[\"mean_test_score\"], cvres_EN[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "print(\"Best_parameters:\", grid_search_EN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation_scores: [68482.68845448 66228.78344341 67860.66652308 66634.56454477\n",
      " 69643.46633766]\n",
      "Cross_validation_mean_score: 67770.03386068033\n"
     ]
    }
   ],
   "source": [
    "final_EN_model = grid_search_EN.best_estimator_ \n",
    "scores_EN = cross_val_score(final_EN_model, housing_tr_poly_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "EN_scores = np.sqrt(-scores_EN)\n",
    "display_scores(EN_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Regression</th>\n",
       "      <th>Linear_Regression_poly_features</th>\n",
       "      <th>Ridge_Regression_poly_features</th>\n",
       "      <th>Lasso_Regression_poly_features</th>\n",
       "      <th>Elastic_net_poly_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69027.220762</td>\n",
       "      <td>6.663858e+14</td>\n",
       "      <td>69910.413787</td>\n",
       "      <td>71437.512937</td>\n",
       "      <td>67770.033861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear_Regression  Linear_Regression_poly_features  \\\n",
       "0       69027.220762                     6.663858e+14   \n",
       "\n",
       "   Ridge_Regression_poly_features  Lasso_Regression_poly_features  \\\n",
       "0                    69910.413787                    71437.512937   \n",
       "\n",
       "   Elastic_net_poly_features  \n",
       "0               67770.033861  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Linear_Regression\":[LR_scores.mean()],\n",
    "             \"Linear_Regression_poly_features\": [LR_scores_poly.mean()],\n",
    "             \"Ridge_Regression_poly_features\": [Ridge_scores.mean()],\n",
    "             \"Lasso_Regression_poly_features\": [Lasso_scores.mean()],\n",
    "             \"Elastic_net_poly_features\": [EN_scores.mean()]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Expected Results\n",
    "\n",
    "Before you compute the final_rmse on the test data using your best model, pause and reflect:\n",
    "- Does your best model have high variance? \n",
    "- Why was your best performing model better than the others?\n",
    "- What is your expected rmse score on your test data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER HERE \n",
    "- My best model so far is using Elastic Net algorithm with Grid Searh to find out good hyperparameters. The best model has 80% l1 regulation + 20% l2 regulation. This model has low variance than other polynomial models. And we could hardly see it is overfitting the train set from cross validation.\n",
    "\n",
    "- This model is better beacuse of two reasons: it firstly reduced the bias from doing the polynomial transformations. Secondly, to avoid high variance, it has regulated using both l1 and l2 regulations. This is achieved by using Elastic Net which is a mixture of both Ridge and Lasso. Therefore this model has a good balance for bias/variance tradeoff.\n",
    "\n",
    "- I would expect simiar rmse score on my test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluating your best model on TESTING data\n",
    "\n",
    "Of the models you created above, choose the best one to test on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_on_test_set: 67187.13083227992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_EN.best_estimator_\n",
    "\n",
    "\n",
    "final_predictions = final_model.predict(housing_test_poly_ss)\n",
    "\n",
    "final_mse = mean_squared_error(final_predictions,housing_test_target) \n",
    "print(\"RMSE_on_test_set:\", final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(housing_test_target, final_predictions) \n",
    "plt.xlim([-200000,800000])\n",
    "plt.ylim([-200000,800000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Try a more advanced model\n",
    "\n",
    "Try a more complex algorithm (SVR, RandomForest, etc.) and see if the accuracy improves (train on the full training set, and then test on the full test set). We have already done this in one of the earlier assignments so this should be easy!\n",
    "\n",
    "Why does the accuracy improve when using a more complex algorithm in this case? Write a very breif answer in the cell below following your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=8, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search_forest = GridSearchCV(forest_reg, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_forest.fit(housing_tr_poly_ss, housing_tr_label)\n",
    "grid_search_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation_scores: [54072.61628329 53352.09265233 52699.2019036  52651.58418643\n",
      " 53905.49115085]\n",
      "Cross_validation_mean_score: 53336.197235300366\n"
     ]
    }
   ],
   "source": [
    "# final train set cross validation scores\n",
    "\n",
    "final_model_forest = grid_search_forest.best_estimator_\n",
    "\n",
    "scores_forest = cross_val_score(final_model_forest, housing_tr_poly_ss, housing_tr_label,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "forest_scores = np.sqrt(-scores_forest)\n",
    "display_scores(forest_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_on_test_set: 66149.48419565713\n"
     ]
    }
   ],
   "source": [
    "final_model_forest = grid_search_forest.best_estimator_\n",
    "final_predictions_forest = final_model_forest.predict(housing_test_poly_ss)\n",
    "\n",
    "final_mse_forest = mean_squared_error(final_predictions_forest,housing_test_target)\n",
    "final_rmse_forest = np.sqrt(final_mse_forest)\n",
    "print(\"RMSE_on_test_set:\", final_rmse_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER HERE \n",
    "For our Elastic Net model, We have used polynomial features, which might bring unncecssary high variance from increasing complexity. Here we have a more complicated model random forest that performs better. This is because the main idea behind random forest is that lots of high variance and low bias trees combine to generate a low bias low variance forest, and it could deal with high variance data better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "For X matrix, eacdh row represents all features for each instance. Each column reprensents all instance values for one specific feature. So XT dot y in equation 4.4 will make sense: a row in XT (a column in X) dot the labes y seting the value for that feature. \n",
    "Also I have tried to prove equation 4.4 by multyplying both side of equation by XT.X. Then from y = X dot theta we could prove equation 4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. If the learning rate is high, then the whole process could diverge instead of converge. If you just let it run you will not get to the minimum cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, mini-batch, although compared to SGD, can reduce the bouncy behaviour of cost function, its cost function still can bounce up and down. We should not stop the iteration immediately when the validation error goes up, since it could be the algothrim is jumping out of the local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter α or reduce it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "This model has high bias. The learning cuves with both validation and training error high and close usually indcate that the model is underfitting. Therefore we should reduce hyperparameter alpha to reduce regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
